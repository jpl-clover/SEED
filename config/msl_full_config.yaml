# default config
defaults: [{ "": "default_config.yaml" }]

# distributed training/slurm arguments
nodes: 1
ngpus_per_node: 2  # number of GPUs per node
node_rank: -1 # machine nr. in node (0 -- nodes - 1)
local_rank: -1  # range: (0 -- num_gpus_per_node - 1)
multiprocessing_distributed: True  # Use DistributedDataProcessing if True

# train options
batch_size: 32
epochs: 10
dataset: "MSL"
dataset_dir: "/home/goh/Documents/CLOVER/data/msl-labeled-data-set-v2.1"

# wandb
use_wandb: true
wandb_project: "moco_test"

# model options
arch: "resnet50"
pretrain: False
resume: ""
model_path: "moco_default_output"  # saves checkpoints to this folder

moco_k: 4096